# -*- coding: utf-8 -*-
"""microsoft.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SjU2S5g-0TL6-46kjj2qsn-2f92J1K-D
"""

! pip install praw

import praw
import pandas as pd
from textblob import TextBlob
from datetime import datetime

reddit = praw.Reddit(
    client_id='rCsEIXZPkqV3WwciMFo3ug',
    client_secret='2xXsGwZWvJAdQAUSusT6Ap52OsLMhg',
    user_agent='microsoft_sentiment_scraper'
)

def scrape_reddit_sentiment(query, subreddits, start_date, end_date):
    posts = []
    for sub in subreddits:
        print(f"Scraping r/{sub}...")
        try:
            subreddit = reddit.subreddit(sub)
            for submission in subreddit.search(query, sort='new', time_filter='all', limit=1000):
                post_date = datetime.utcfromtimestamp(submission.created_utc).date()
                if start_date <= post_date <= end_date:
                    text = submission.title + " " + submission.selftext
                    sentiment = TextBlob(text).sentiment.polarity
                    posts.append({
                        'date': post_date,
                        'title': submission.title,
                        'text': submission.selftext,
                        'subreddit': sub,
                        'sentiment': sentiment
                    })
        except Exception as e:
            print(f"[ERROR] r/{sub}: {e}")
    return pd.DataFrame(posts)

subreddits = ['stocks', 'investing', 'wallstreetbets', 'Microsoft', 'technology', 'finance', 'gadgets']
query = 'Microsoft OR MSFT OR "Microsoft Corp" OR Windows OR Azure OR Office365'
start_date = datetime(2020, 1, 1).date()
end_date = datetime(2025, 6, 1).date()

reddit_df = scrape_reddit_sentiment(query, subreddits, start_date, end_date)
reddit_df.to_csv('microsoft_reddit_sentiment.csv', index=False)

!pip install vaderSentiment afinn textblob

import re
from nltk.stem import PorterStemmer
import nltk

nltk.download('punkt')

stemmer = PorterStemmer()

reddit_df['combined_text'] = reddit_df['title'].fillna('') + ' ' + reddit_df['text'].fillna('')


reddit_df['cleaned'] = reddit_df['combined_text'].apply(lambda x: re.sub("http\S+", "", x))

reddit_df['cleaned'] = reddit_df['cleaned'].apply(lambda x: re.sub("[^a-zA-Z\s]", "", x))

reddit_df['cleaned'] = reddit_df['cleaned'].apply(lambda x: x.lower())

reddit_df['cleaned'] = reddit_df['cleaned'].apply(lambda x: re.sub("\s+", " ", x).strip())

reddit_df['cleaned'] = reddit_df['cleaned'].apply(
    lambda x: " ".join([stemmer.stem(word) for word in x.split()])
)

print(reddit_df[['date', 'title', 'cleaned']].head())

from textblob import TextBlob

reddit_df['textblob_polarity'] = reddit_df['cleaned'].apply(lambda x: TextBlob(x).sentiment.polarity)

print(reddit_df[['cleaned', 'textblob_polarity']].head())

from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

vader = SentimentIntensityAnalyzer()

reddit_df['vader_compound'] = reddit_df['cleaned'].apply(lambda x: vader.polarity_scores(x)['compound'])

print(reddit_df[['cleaned', 'vader_compound']].head())

import nltk
nltk.download('opinion_lexicon')

from afinn import Afinn

afinn = Afinn()

reddit_df['afinn_score'] = reddit_df['cleaned'].apply(lambda x: afinn.score(x))

print(reddit_df[['cleaned', 'afinn_score']].head())

import nltk
from nltk.corpus import opinion_lexicon

nltk.download('opinion_lexicon')

positive_words = set(opinion_lexicon.positive())
negative_words = set(opinion_lexicon.negative())

def bing(text):
    words = text.split()
    pos = sum(1 for word in words if word in positive_words)
    neg = sum(1 for word in words if word in negative_words)
    return pos - neg

reddit_df['bing_score'] = reddit_df['cleaned'].apply(bing)

print(reddit_df[['cleaned', 'bing_score']].head())

from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline

model_name = "ProsusAI/finbert"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

finbert = pipeline(
    "sentiment-analysis",
    model=model,
    tokenizer=tokenizer,
    truncation=True,
    max_length=512
)

def safe(text, char_limit=2000):
    """
    Truncate text to a safe character length (approx. 512 BERT tokens)
    """
    return text[:char_limit]

reddit_df['cleaned_trunc'] = reddit_df['cleaned'].fillna('').apply(safe)

def run_finbert(text):
    try:
        result = finbert(text)[0]
        label = result['label']
        score = result['score']

        if label == 'positive':
            return +1 * score
        elif label == 'negative':
            return -1 * score
        else:
             return score
    except Exception as e:
        print(f"Error on text: {text[:30]}...: {e}")
        return 0

reddit_df['finbert_sentiment'] = reddit_df['cleaned_trunc'].apply(run_finbert)

print(reddit_df[['cleaned_trunc', 'finbert_sentiment']].head())


reddit_df.to_csv('microsoft_reddit_sentiment.csv', index=False)

from google.colab import files
up = files.upload()

import pandas as pd

df = pd.read_csv('microsoft_reddit_sentiment.csv')

df

sample_micro = df.sample(n=300, random_state=42)

sample_micro.to_csv("sample_micro.csv", index=False)

files.download("sample_micro.csv")

files.upload()

df1= pd.read_csv('microsoft_stock_2020_2025.csv')

df1

from google.colab import files
up= files.upload()

df= pd.read_excel("microsoft_combine.xlsx")

df["finbert_edited"]=df["finbert"]
for i in range(1,len(df)):
  today_close= df.loc[i,"close"]
  today_sentiment=df.loc[i,"finbert"]
  yesterday_close=df.loc[i-1,"close"]
  yesterday_sentiment=df.loc[i-1, "finbert"]
  if pd.notnull(today_close) and pd.isnull(today_sentiment):
    if pd.isnull(yesterday_close) and pd.notnull(yesterday_sentiment):
      df1.loc[i,"finbert_edited"]=yesterday_sentiment

df

merged_df = df.dropna(subset=['close']).reset_index(drop=True)

merged_df

merged_df = merged_df.fillna(0)

merged_df

corr= merged_df.corr()

merged_df = merged_df[['date', 'close', 'finbert_edited']]

import seaborn as sns
import matplotlib.pyplot as plt

sns.heatmap(corr, annot=True, cmap="coolwarm")
plt.show()

merged_df.to_csv('microsoft_final.csv', index=False)



files.download("microsoft_final.csv")

from google.colab import files
up= files.upload()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('microsoft_final.csv')

df.isnull().sum()

df.info()

df.describe()

plt.figure(figsize=(12, 6))
plt.plot(df['close'], label='Close Price')
plt.title("Stock Closing Price (2020–2025)")
plt.xlabel("Date")
plt.ylabel("Price (USD)")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, GRU, Dense

df['date'] = pd.to_datetime(df['date'])
df.set_index('date', inplace=True)

scaler = MinMaxScaler()
scaled = scaler.fit_transform(df[['close']].values)

def create_sequences(data, seq_len):
    X, y = [], []
    for i in range(len(data) - seq_len):
        X.append(data[i:i+seq_len])
        y.append(data[i+seq_len])
    return np.array(X), np.array(y)

seq_len = 60
X, y = create_sequences(scaled, seq_len)

split = int(len(X) * 0.8)
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]


X_train = X_train.reshape(-1, seq_len, 1)
X_test = X_test.reshape(-1, seq_len, 1)

model = Sequential([
    LSTM(50, return_sequences=False, input_shape=(seq_len, 1)),
    Dense(1)
])
model.compile(optimizer='adam', loss='mean_squared_error')

model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), verbose=1)
y_pred = model.predict(X_test)

plt.figure(figsize=(10, 5))
plt.plot(y_test, label='True Price')
plt.plot(y_pred, label='LSTM Prediction')
plt.title('LSTM Forecast')
plt.xlabel('Time')
plt.ylabel('Price')
plt.legend()
plt.show()

residuals = y_test.flatten() - y_pred.flatten()
import matplotlib.pyplot as plt
import pandas as pd


plt.figure(figsize=(12, 5))
plt.plot(residuals, label='Residuals', color='purple')
plt.axhline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Residual Plot ')
plt.xlabel('Time')
plt.ylabel('Residual (Actual - Predicted)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()


plt.figure(figsize=(7, 5))
plt.hist(residuals, bins=30, color='skyblue', edgecolor='black')
plt.title('Distribution of Residuals')
plt.xlabel('Residual Value')
plt.ylabel('Frequency')
plt.axvline(0, color='red', linestyle='--')
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import gaussian_kde

residuals = np.array(residuals)

kde = gaussian_kde(residuals)
x_vals = np.linspace(residuals.min(), residuals.max(), 1000)
kde_vals = kde(x_vals)

plt.figure(figsize=(7, 5))
plt.hist(residuals, bins=30, color='skyblue', edgecolor='black', alpha=0.6, density=True)
plt.plot(x_vals, kde_vals, color='darkblue', linewidth=2, label='Density Curve')
plt.axvline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Distribution of Residuals with Density Curve')
plt.xlabel('Residual Value')
plt.ylabel('Density')
plt.legend()
plt.tight_layout()
plt.show()

from sklearn.metrics import mean_squared_error

mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)

print(f'MSE: {mse:.4f}')
print(f'RMSE: {rmse:.4f}')

from sklearn.metrics import mean_absolute_error, r2_score

mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'MAE: {mae:.4f}')
print(f'R² Score: {r2:.4f}')

model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(seq_len, 1)))
model.add(LSTM(32))
model.add(Dense(1))

model.compile(optimizer='adam', loss='mean_squared_error')
model.summary()

model_fit= model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))
pred = model.predict(X_test)

residuals = y_test.flatten() - pred.flatten()
import matplotlib.pyplot as plt
import pandas as pd


plt.figure(figsize=(12, 5))
plt.plot(residuals, label='Residuals', color='purple')
plt.axhline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Residual Plot ')
plt.xlabel('Time')
plt.ylabel('Residual (Actual - Predicted)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()


plt.figure(figsize=(7, 5))
plt.hist(residuals, bins=30, color='skyblue', edgecolor='black')
plt.title('Distribution of Residuals')
plt.xlabel('Residual Value')
plt.ylabel('Frequency')
plt.axvline(0, color='red', linestyle='--')
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import gaussian_kde

residuals = np.array(residuals)

kde = gaussian_kde(residuals)
x_vals = np.linspace(residuals.min(), residuals.max(), 1000)
kde_vals = kde(x_vals)

plt.figure(figsize=(7, 5))
plt.hist(residuals, bins=30, color='skyblue', edgecolor='black', alpha=0.6, density=True)
plt.plot(x_vals, kde_vals, color='darkblue', linewidth=2, label='Density Curve')
plt.axvline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Distribution of Residuals with Density Curve')
plt.xlabel('Residual Value')
plt.ylabel('Density')
plt.legend()
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

plt.figure(figsize=(10,6))
plt.plot(y_test, label='Actual')
plt.plot(pred, label='Predicted', linestyle='--')
plt.legend()
plt.title("2-Layer LSTM without Sentiment")
plt.show()

mae = mean_absolute_error(y_test, pred)
r2 = r2_score(y_test, pred)

print(f'MAE: {mae:.4f}')
print(f'R² Score: {r2:.4f}')

rmse = np.sqrt(mean_squared_error(y_test, pred))
print(f'RMSE: {rmse:.4f}')
mse = mean_squared_error(y_test, pred)
print(f'MSE: {mse:.4f}')

from tensorflow.keras.layers import  Bidirectional
model = Sequential()
model.add(Bidirectional(LSTM(50), input_shape=(seq_len, 1)))
model.add(Dense(1))

model.compile(optimizer='adam', loss='mean_squared_error')
bi_fit = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))
bi_pred = model.predict(X_test)

residuals = y_test.flatten() - bi_pred.flatten()
import matplotlib.pyplot as plt
import pandas as pd


plt.figure(figsize=(12, 5))
plt.plot(residuals, label='Residuals', color='purple')
plt.axhline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Residual Plot')
plt.xlabel('Time')
plt.ylabel('Residual (Actual - Predicted)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()


plt.figure(figsize=(7, 5))
plt.hist(residuals, bins=30, color='skyblue', edgecolor='black')
plt.title('Distribution of Residuals')
plt.xlabel('Residual Value')
plt.ylabel('Frequency')
plt.axvline(0, color='red', linestyle='--')
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import gaussian_kde

residuals = np.array(residuals)

kde = gaussian_kde(residuals)
x_vals = np.linspace(residuals.min(), residuals.max(), 1000)
kde_vals = kde(x_vals)

plt.figure(figsize=(7, 5))
plt.hist(residuals, bins=30, color='skyblue', edgecolor='black', alpha=0.6, density=True)
plt.plot(x_vals, kde_vals, color='darkblue', linewidth=2, label='Density Curve')
plt.axvline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Distribution of Residuals with Density Curve')
plt.xlabel('Residual Value')
plt.ylabel('Density')
plt.legend()
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import gaussian_kde

residuals = np.array(residuals)

kde = gaussian_kde(residuals)
x_vals = np.linspace(residuals.min(), residuals.max(), 1000)
kde_vals = kde(x_vals)

plt.figure(figsize=(7, 5))
plt.hist(residuals, bins=30, color='skyblue', edgecolor='black', alpha=0.6, density=True)
plt.plot(x_vals, kde_vals, color='darkblue', linewidth=2, label='Density Curve')
plt.axvline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Distribution of Residuals with Density Curve')
plt.xlabel('Residual Value')
plt.ylabel('Density')
plt.legend()
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

plt.figure(figsize=(10,6))
plt.plot(y_test, label='Actual')
plt.plot(bi_pred, label='Bi-LSTM Predicted', linestyle='--')
plt.legend()
plt.title("Bi-LSTM without Sentiment")
plt.show()

rmse = np.sqrt(mean_squared_error(y_test, bi_pred))
print(f'RMSE: {rmse:.4f}')
mse = mean_squared_error(y_test, bi_pred)
print(f'MSE: {mse:.4f}')
r2 = r2_score(y_test, bi_pred)
print(f'R² Score: {r2:.4f}')
mae = mean_absolute_error(y_test, bi_pred)
print(f'MAE: {mae:.4f}')

from tensorflow.keras.layers import GRU

model = Sequential([
    GRU(50, return_sequences=False, input_shape=(seq_len, 1)),
    Dense(1)
])
model.compile(optimizer='adam', loss='mean_squared_error')

model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=1)
y_pred = model.predict(X_test)



plt.figure(figsize=(10, 5))
plt.plot(y_test, label='True Price')
plt.plot(y_pred, label='GRU Prediction')
plt.title('GRU Forecast')
plt.xlabel('Time')
plt.ylabel('Price')
plt.legend()
plt.show()

residuals = y_test.flatten() - y_pred.flatten()
import matplotlib.pyplot as plt
import pandas as pd


plt.figure(figsize=(12, 5))
plt.plot(residuals, label='Residuals', color='purple')
plt.axhline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Residual Plot')
plt.xlabel('Time')
plt.ylabel('Residual (Actual - Predicted)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()


plt.figure(figsize=(7, 5))
plt.hist(residuals, bins=30, color='skyblue', edgecolor='black')
plt.title('Distribution of Residuals')
plt.xlabel('Residual Value')
plt.ylabel('Frequency')
plt.axvline(0, color='red', linestyle='--')
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import gaussian_kde

residuals = np.array(residuals)

kde = gaussian_kde(residuals)
x_vals = np.linspace(residuals.min(), residuals.max(), 1000)
kde_vals = kde(x_vals)

plt.figure(figsize=(7, 5))
plt.hist(residuals, bins=30, color='skyblue', edgecolor='black', alpha=0.6, density=True)
plt.plot(x_vals, kde_vals, color='darkblue', linewidth=2, label='Density Curve')
plt.axvline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Distribution of Residuals with Density Curve')
plt.xlabel('Residual Value')
plt.ylabel('Density')
plt.legend()
plt.tight_layout()
plt.show()

from tensorflow.keras.layers import GRU

m = Sequential([
    GRU(50, return_sequences=False, input_shape=(seq_len, 1)),
    Dense(1)
])
m.compile(optimizer='adam', loss='mean_squared_error')

m.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=1)
y = model.predict(X_test)

from sklearn.metrics import mean_squared_error

mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)

print(f'MSE: {mse:.4f}')
print(f'RMSE: {rmse:.4f}')

from sklearn.metrics import mean_absolute_error, r2_score

mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'MAE: {mae:.4f}')
print(f'R² Score: {r2:.4f}')

model = Sequential()
model.add(GRU(units=50, return_sequences=True, input_shape=(seq_len, 1)))
model.add(GRU(units=32))
model.add(Dense(1))

model.compile(optimizer='adam', loss='mean_squared_error')

gru_1 = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))
pred_gru = model.predict(X_test)

residuals = y_test.flatten() - pred_gru.flatten()
import matplotlib.pyplot as plt
import pandas as pd


plt.figure(figsize=(12, 5))
plt.plot(residuals, label='Residuals', color='purple')
plt.axhline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Residual Plot ')
plt.xlabel('Time')
plt.ylabel('Residual (Actual - Predicted)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()


plt.figure(figsize=(7, 5))
plt.hist(residuals, bins=30, color='skyblue', edgecolor='black')
plt.title('Distribution of Residuals')
plt.xlabel('Residual Value')
plt.ylabel('Frequency')
plt.axvline(0, color='red', linestyle='--')
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import gaussian_kde

residuals = np.array(residuals)

kde = gaussian_kde(residuals)
x_vals = np.linspace(residuals.min(), residuals.max(), 1000)
kde_vals = kde(x_vals)

plt.figure(figsize=(7, 5))
plt.hist(residuals, bins=30, color='skyblue', edgecolor='black', alpha=0.6, density=True)
plt.plot(x_vals, kde_vals, color='darkblue', linewidth=2, label='Density Curve')
plt.axvline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Distribution of Residuals with Density Curve')
plt.xlabel('Residual Value')
plt.ylabel('Density')
plt.legend()
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

plt.figure(figsize=(10,6))
plt.plot(y_test, label='Actual')
plt.plot(pred_gru, label='2-Layer GRU Predicted', linestyle='--')
plt.legend()
plt.title("2-Layer GRU without Sentiment")
plt.show()

rmse= np.sqrt(mean_squared_error(y_test, pred_gru))
print(f'RMSE: {rmse:.4f}')
mse = mean_squared_error(y_test, pred_gru)
print(f'MSE: {mse:.4f}')
r2 = r2_score(y_test, pred_gru)
print(f'R² Score: {r2:.4f}')
mae = mean_absolute_error(y_test, pred_gru)
print(f'MAE: {mae:.4f}')

model = Sequential()
model.add(Bidirectional(
    GRU(units=50),
    input_shape=(seq_len, 1)
))
model.add(Dense(1))

model.compile(optimizer='adam', loss='mean_squared_error')
model.summary()

bi_gru = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))

bi_gru = model.predict(X_test)

residuals = y_test.flatten() - bi_gru.flatten()
import matplotlib.pyplot as plt
import pandas as pd


plt.figure(figsize=(12, 5))
plt.plot(residuals, label='Residuals', color='purple')
plt.axhline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Residual Plot ')
plt.xlabel('Time')
plt.ylabel('Residual (Actual - Predicted)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()


plt.figure(figsize=(7, 5))
plt.hist(residuals, bins=30, color='skyblue', edgecolor='black')
plt.title('Distribution of Residuals')
plt.xlabel('Residual Value')
plt.ylabel('Frequency')
plt.axvline(0, color='red', linestyle='--')
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import gaussian_kde

residuals = np.array(residuals)

kde = gaussian_kde(residuals)
x_vals = np.linspace(residuals.min(), residuals.max(), 1000)
kde_vals = kde(x_vals)

plt.figure(figsize=(7, 5))
plt.hist(residuals, bins=30, color='skyblue', edgecolor='black', alpha=0.6, density=True)
plt.plot(x_vals, kde_vals, color='darkblue', linewidth=2, label='Density Curve')
plt.axvline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Distribution of Residuals with Density Curve')
plt.xlabel('Residual Value')
plt.ylabel('Density')
plt.legend()
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

plt.figure(figsize=(10,6))
plt.plot(y_test, label='Actual')
plt.plot(bi_gru, label='Bi-GRU Predicted', linestyle='--')
plt.legend()
plt.title("Bi-directional GRU with Sentiment")
plt.show()

rmse= np.sqrt(mean_squared_error(y_test, bi_gru))
print(f'RMSE: {rmse:.4f}')
mae = mean_absolute_error(y_test, bi_gru)
print(f'MAE: {mae:.4f}')
mse = mean_squared_error(y_test, bi_gru)
print(f'MSE: {mse:.4f}')
r2 = r2_score(y_test, bi_gru)
print(f'R² Score: {r2:.4f}')

df['sentiment_shifted'] = df['finbert_edited'].shift(2)

corr = df.corr()
sns.heatmap(corr, annot=True, cmap="coolwarm")
plt.show()

"""validation

"""

import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, f1_score



df_clean = df.dropna(subset=['label'])

true_labels = df_clean['label'].values
scores = df_clean['finbert'].values


def find_best_thresholds(scores, true_labels):
    best_pos, best_neg = 0.1, -0.1
    best_f1 = 0
    pos_range = np.linspace(0, max(scores), 50)
    neg_range = np.linspace(min(scores), 0, 50)
    for pos_th in pos_range:
        for neg_th in neg_range:
            preds = []
            for s in scores:
                if s > pos_th:
                    preds.append('positive')
                elif s < neg_th:
                    preds.append('negative')
                else:
                    preds.append('neutral')
            f1 = f1_score(true_labels, preds, average='weighted', zero_division=0)
            if f1 > best_f1:
                best_f1 = f1
                best_pos = pos_th
                best_neg = neg_th
    return best_pos, best_neg, best_f1

best_pos, best_neg, best_f1 = find_best_thresholds(scores, true_labels)
print(f"Best thresholds: positive > {best_pos:.3f}, negative < {best_neg:.3f}, with F1 = {best_f1:.3f}")


def score_to_label(score):
    if score > best_pos:
        return 'positive'
    elif score < best_neg:
        return 'negative'
    else:
        return 'neutral'

preds = [score_to_label(s) for s in scores]


accuracy = accuracy_score(true_labels, preds)
precision, recall, f1, _ = precision_recall_fscore_support(true_labels, preds, average='weighted', zero_division=0)
cm = confusion_matrix(true_labels, preds, labels=['positive', 'neutral', 'negative'])

print(f"Accuracy: {accuracy:.3f}")
print(f"Precision: {precision:.3f}")
print(f"Recall: {recall:.3f}")
print(f"F1-score: {f1:.3f}")
print("Confusion Matrix:")
print(cm)

import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, f1_score


df = pd.read_excel('labeled.xlsx')
df_clean = df.dropna(subset=['label'])

true_labels = df_clean['label'].values
scores = df_clean['afinn'].values


def find_best_thresholds(scores, true_labels):
    best_pos, best_neg = 0.1, -0.1
    best_f1 = 0
    pos_range = np.linspace(0, max(scores), 50)
    neg_range = np.linspace(min(scores), 0, 50)
    for pos_th in pos_range:
        for neg_th in neg_range:
            preds = []
            for s in scores:
                if s > pos_th:
                    preds.append('positive')
                elif s < neg_th:
                    preds.append('negative')
                else:
                    preds.append('neutral')
            f1 = f1_score(true_labels, preds, average='weighted', zero_division=0)
            if f1 > best_f1:
                best_f1 = f1
                best_pos = pos_th
                best_neg = neg_th
    return best_pos, best_neg, best_f1

best_pos, best_neg, best_f1 = find_best_thresholds(scores, true_labels)
print(f"Best thresholds: positive > {best_pos:.3f}, negative < {best_neg:.3f}, with F1 = {best_f1:.3f}")


def score_to_label(score):
    if score > best_pos:
        return 'positive'
    elif score < best_neg:
        return 'negative'
    else:
        return 'neutral'

preds = [score_to_label(s) for s in scores]


accuracy = accuracy_score(true_labels, preds)
precision, recall, f1, _ = precision_recall_fscore_support(true_labels, preds, average='weighted', zero_division=0)
cm = confusion_matrix(true_labels, preds, labels=['positive', 'neutral', 'negative'])

print(f"Accuracy: {accuracy:.3f}")
print(f"Precision: {precision:.3f}")
print(f"Recall: {recall:.3f}")
print(f"F1-score: {f1:.3f}")
print("Confusion Matrix:")
print(cm)

import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, f1_score


df = pd.read_excel('labeled.xlsx')
df_clean = df.dropna(subset=['label'])

true_labels = df_clean['label'].values
scores = df_clean['vader'].values


def find_best_thresholds(scores, true_labels):
    best_pos, best_neg = 0.1, -0.1
    best_f1 = 0
    pos_range = np.linspace(0, max(scores), 50)
    neg_range = np.linspace(min(scores), 0, 50)
    for pos_th in pos_range:
        for neg_th in neg_range:
            preds = []
            for s in scores:
                if s > pos_th:
                    preds.append('positive')
                elif s < neg_th:
                    preds.append('negative')
                else:
                    preds.append('neutral')
            f1 = f1_score(true_labels, preds, average='weighted', zero_division=0)
            if f1 > best_f1:
                best_f1 = f1
                best_pos = pos_th
                best_neg = neg_th
    return best_pos, best_neg, best_f1

best_pos, best_neg, best_f1 = find_best_thresholds(scores, true_labels)
print(f"Best thresholds: positive > {best_pos:.3f}, negative < {best_neg:.3f}, with F1 = {best_f1:.3f}")


def score_to_label(score):
    if score > best_pos:
        return 'positive'
    elif score < best_neg:
        return 'negative'
    else:
        return 'neutral'

preds = [score_to_label(s) for s in scores]


accuracy = accuracy_score(true_labels, preds)
precision, recall, f1, _ = precision_recall_fscore_support(true_labels, preds, average='weighted', zero_division=0)
cm = confusion_matrix(true_labels, preds, labels=['positive', 'neutral', 'negative'])

print(f"Accuracy: {accuracy:.3f}")
print(f"Precision: {precision:.3f}")
print(f"Recall: {recall:.3f}")
print(f"F1-score: {f1:.3f}")
print("Confusion Matrix:")
print(cm)

import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, f1_score


df = pd.read_excel('labeled.xlsx')
df_clean = df.dropna(subset=['label'])

true_labels = df_clean['label'].values
scores = df_clean['textblob'].values


def find_best_thresholds(scores, true_labels):
    best_pos, best_neg = 0.1, -0.1
    best_f1 = 0
    pos_range = np.linspace(0, max(scores), 50)
    neg_range = np.linspace(min(scores), 0, 50)
    for pos_th in pos_range:
        for neg_th in neg_range:
            preds = []
            for s in scores:
                if s > pos_th:
                    preds.append('positive')
                elif s < neg_th:
                    preds.append('negative')
                else:
                    preds.append('neutral')
            f1 = f1_score(true_labels, preds, average='weighted', zero_division=0)
            if f1 > best_f1:
                best_f1 = f1
                best_pos = pos_th
                best_neg = neg_th
    return best_pos, best_neg, best_f1

best_pos, best_neg, best_f1 = find_best_thresholds(scores, true_labels)
print(f"Best thresholds: positive > {best_pos:.3f}, negative < {best_neg:.3f}, with F1 = {best_f1:.3f}")


def score_to_label(score):
    if score > best_pos:
        return 'positive'
    elif score < best_neg:
        return 'negative'
    else:
        return 'neutral'

preds = [score_to_label(s) for s in scores]


accuracy = accuracy_score(true_labels, preds)
precision, recall, f1, _ = precision_recall_fscore_support(true_labels, preds, average='weighted', zero_division=0)
cm = confusion_matrix(true_labels, preds, labels=['positive', 'neutral', 'negative'])

print(f"Accuracy: {accuracy:.3f}")
print(f"Precision: {precision:.3f}")
print(f"Recall: {recall:.3f}")
print(f"F1-score: {f1:.3f}")
print("Confusion Matrix:")
print(cm)

from google.colab import files
up = files.upload()

import pandas as pd
import numpy as np
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

df = pd.read_csv("microsoft_final.csv")

df.info()

df.describe()

scaler = MinMaxScaler()
scaled = scaler.fit_transform(df[['close', 'finbert_edited']])

def create_sequences(data, seq_len):
    X, y = [], []
    for i in range(len(data) - seq_len):
        X.append(data[i:i + seq_len])
        y.append(data[i + seq_len , 0])
    return np.array(X), np.array(y)

seq_len = 60
X, y = create_sequences(scaled, seq_len)

split = int(len(X) * 0.8)
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]



model = Sequential([
    LSTM(50, input_shape=(seq_len, 2)),
    Dense(1)
])
model.compile(optimizer='adam', loss='mean_squared_error')

model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))


y_pred = model.predict(X_test)

residuals = y_test.flatten() - y_pred.flatten()
import matplotlib.pyplot as plt
import pandas as pd


plt.figure(figsize=(12, 5))
plt.plot(residuals, label='Residuals', color='purple')
plt.axhline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Residual Plot ')
plt.xlabel('Time')
plt.ylabel('Residual (Actual - Predicted)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()


plt.figure(figsize=(7, 5))
plt.hist(residuals, bins=30, color='skyblue', edgecolor='black')
plt.title('Distribution of Residuals')
plt.xlabel('Residual Value')
plt.ylabel('Frequency')
plt.axvline(0, color='red', linestyle='--')
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import gaussian_kde

residuals = np.array(residuals)

kde = gaussian_kde(residuals)
x_vals = np.linspace(residuals.min(), residuals.max(), 1000)
kde_vals = kde(x_vals)

plt.figure(figsize=(7, 5))
plt.hist(residuals, bins=30, color='skyblue', edgecolor='black', alpha=0.6, density=True)
plt.plot(x_vals, kde_vals, color='darkblue', linewidth=2, label='Density Curve')
plt.axvline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Distribution of Residuals with Density Curve')
plt.xlabel('Residual Value')
plt.ylabel('Density')
plt.legend()
plt.tight_layout()
plt.show()



r2 = r2_score(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)

print(f"R² Score: {r2:.4f}")
print(f"MSE     : {mse:.4f}")
print(f"RMSE    : {rmse:.4f}")
print(f"MAE     : {mae:.4f}")

plt.figure(figsize=(12, 6))
plt.plot(y_test, label='Actual (scaled)', color='blue')
plt.plot(y_pred, label='Predicted (scaled)', color='green')
plt.title('LSTM with FinBERT Sentiment')
plt.xlabel('Time')
plt.ylabel('Scaled Price')
plt.legend()
plt.grid(True)
plt.show()

model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(seq_len, 2)))
model.add(LSTM(32))
model.add(Dense(1))

model.compile(optimizer='adam', loss='mean_squared_error')
model.summary()

model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))
pred = model.predict(X_test)

residuals = y_test.flatten() - pred.flatten()
import matplotlib.pyplot as plt
import pandas as pd


plt.figure(figsize=(12, 5))
plt.plot(residuals, label='Residuals', color='purple')
plt.axhline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Residual Plot ')
plt.xlabel('Time')
plt.ylabel('Residual (Actual - Predicted)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()


plt.figure(figsize=(7, 5))
plt.hist(residuals, bins=30, color='skyblue', edgecolor='black')
plt.title('Distribution of Residuals')
plt.xlabel('Residual Value')
plt.ylabel('Frequency')
plt.axvline(0, color='red', linestyle='--')
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import gaussian_kde


residuals = np.array(residuals)


kde = gaussian_kde(residuals)
x_vals = np.linspace(residuals.min(), residuals.max(), 1000)
kde_vals = kde(x_vals)


plt.figure(figsize=(7, 5))
plt.hist(residuals, bins=30, color='skyblue', edgecolor='black', alpha=0.6, density=True)
plt.plot(x_vals, kde_vals, color='darkblue', linewidth=2, label='Density Curve')
plt.axvline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Distribution of Residuals with Density Curve')
plt.xlabel('Residual Value')
plt.ylabel('Density')
plt.legend()
plt.tight_layout()
plt.show()

r2 = r2_score(y_test, pred)
mse = mean_squared_error(y_test, pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, pred)

print(f"R² Score: {r2:.4f}")
print(f"MSE     : {mse:.4f}")
print(f"RMSE    : {rmse:.4f}")
print(f"MAE     : {mae:.4f}")

from tensorflow.keras.layers import  Bidirectional
model = Sequential()
model.add(Bidirectional(LSTM(50), input_shape=(seq_len, 2)))
model.add(Dense(1))

model.compile(optimizer='adam', loss='mean_squared_error')
bi_fit = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))
bi_pred = model.predict(X_test).flatten()

residuals = y_test.flatten() - bi_pred.flatten()
import matplotlib.pyplot as plt
import pandas as pd


plt.figure(figsize=(12, 5))
plt.plot(residuals, label='Residuals', color='purple')
plt.axhline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Residual Plot ')
plt.xlabel('Time')
plt.ylabel('Residual (Actual - Predicted)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()


plt.figure(figsize=(7, 5))
plt.hist(residuals, bins=30, color='skyblue', edgecolor='black')
plt.title('Distribution of Residuals')
plt.xlabel('Residual Value')
plt.ylabel('Frequency')
plt.axvline(0, color='red', linestyle='--')
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import gaussian_kde


residuals = np.array(residuals)


kde = gaussian_kde(residuals)
x_vals = np.linspace(residuals.min(), residuals.max(), 1000)
kde_vals = kde(x_vals)


plt.figure(figsize=(7, 5))
plt.hist(residuals, bins=30, color='skyblue', edgecolor='black', alpha=0.6, density=True)
plt.plot(x_vals, kde_vals, color='darkblue', linewidth=2, label='Density Curve')
plt.axvline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Distribution of Residuals with Density Curve')
plt.xlabel('Residual Value')
plt.ylabel('Density')
plt.legend()
plt.tight_layout()
plt.show()

from tensorflow.keras.layers import  GRU

r2 = r2_score(y_test, bi_pred)
print(f'R² Score: {r2:.4f}')
mse = mean_squared_error(y_test, bi_pred)
print(f'MSE: {mse:.4f}')
mae = mean_absolute_error(y_test, bi_pred)
print(f'MAE: {mae:.4f}')
rmse = np.sqrt(mse)
print(f'RMSE: {rmse:.4f}')

split = int(len(X) * 0.8)
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]

from tensorflow.keras.layers import GRU

model = Sequential([
    GRU(50, input_shape=(seq_len, 2)),
    Dense(1)
])

model.compile(optimizer='adam', loss='mean_squared_error')

model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))


y_pred = model.predict(X_test)

residuals = y_test.flatten() - y_pred.flatten()
import matplotlib.pyplot as plt
import pandas as pd


plt.figure(figsize=(12, 5))
plt.plot(residuals, label='Residuals', color='purple')
plt.axhline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Residual Plot ')
plt.xlabel('Time')
plt.ylabel('Residual (Actual - Predicted)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()


plt.figure(figsize=(7, 5))
plt.hist(residuals, bins=30, color='skyblue', edgecolor='black')
plt.title('Distribution of Residuals')
plt.xlabel('Residual Value')
plt.ylabel('Frequency')
plt.axvline(0, color='red', linestyle='--')
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import gaussian_kde

residuals = np.array(residuals)

kde = gaussian_kde(residuals)
x_vals = np.linspace(residuals.min(), residuals.max(), 1000)
kde_vals = kde(x_vals)

plt.figure(figsize=(7, 5))
plt.hist(residuals, bins=30, color='skyblue', edgecolor='black', alpha=0.6, density=True)
plt.plot(x_vals, kde_vals, color='darkblue', linewidth=2, label='Density Curve')
plt.axvline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Distribution of Residuals with Density Curve')
plt.xlabel('Residual Value')
plt.ylabel('Density')
plt.legend()
plt.tight_layout()
plt.show()

r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)

print(f"R² Score: {r2:.4f}")
print(f"MAE: {mae:.4f}")
print(f"MSE: {mse:.4f}")
print(f"RMSE: {rmse:.4f}")

"""GRU layer 1 was the best model among all

"""

import matplotlib.pyplot as plt
plt.figure(figsize=(12, 6))
plt.plot(y_test, label='Actual Price')
plt.plot(y_pred, label='Predicted Price')
plt.xlabel('Time')
plt.ylabel('Price')
plt.legend()

results = pd.DataFrame({
    'Actual': y_test.flatten(),
    'Predicted': y_pred.flatten()
})

results

results['Prev_Predicted'] = results['Predicted'].shift(1)
results['Signal'] = results.apply(lambda x:
    'Buy' if x['Predicted'] > x['Prev_Predicted'] * 1.005 else
    'Sell' if x['Predicted'] < x['Prev_Predicted'] * 0.995 else
    'Hold', axis=1)

results.dropna(inplace=True)


print(results[['Actual', 'Predicted', 'Signal']])

import seaborn as sns
import matplotlib.pyplot as plt


custom_palette = {
    'Buy': 'mediumseagreen',
    'Sell': 'red',
    'Hold': 'blue'   }

plt.figure(figsize=(12, 5))
sns.scatterplot(
    x=range(len(results)),
    y=results['Predicted'],
    hue=results['Signal'],
    palette=custom_palette
)
plt.title("Trading Signals Based on GRU layer 2 Forecast")
plt.xlabel("Time")
plt.ylabel("Predicted Price")
plt.legend(title='Signal')
plt.show()

import seaborn as sns
plt.figure(figsize=(12, 5))
sns.scatterplot(x=range(len(results)), y=results['Predicted'], hue=results['Signal'], palette='Set1')
plt.title("Trading Signals Based on GRU Forecast")
plt.xlabel("Time")
plt.ylabel("Predicted Price")
plt.show()

model = Sequential()
model.add(GRU(units=50, return_sequences=True, input_shape=(seq_len, 2)))
model.add(GRU(units=32))
model.add(Dense(1))

model.compile(optimizer='adam', loss='mean_squared_error')

model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))
pred = model.predict(X_test)

residuals = y_test.flatten() - pred.flatten()
import matplotlib.pyplot as plt
import pandas as pd


plt.figure(figsize=(12, 5))
plt.plot(residuals, label='Residuals', color='purple')
plt.axhline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Residual Plot ')
plt.xlabel('Time')
plt.ylabel('Residual (Actual - Predicted)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()


plt.figure(figsize=(7, 5))
plt.hist(residuals, bins=30, color='skyblue', edgecolor='black')
plt.title('Distribution of Residuals')
plt.xlabel('Residual Value')
plt.ylabel('Frequency')
plt.axvline(0, color='red', linestyle='--')
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import gaussian_kde

residuals = np.array(residuals)

kde = gaussian_kde(residuals)
x_vals = np.linspace(residuals.min(), residuals.max(), 1000)
kde_vals = kde(x_vals)

plt.figure(figsize=(7, 5))
plt.hist(residuals, bins=30, color='skyblue', edgecolor='black', alpha=0.6, density=True)
plt.plot(x_vals, kde_vals, color='darkblue', linewidth=2, label='Density Curve')
plt.axvline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Distribution of Residuals with Density Curve')
plt.xlabel('Residual Value')
plt.ylabel('Density')
plt.legend()
plt.tight_layout()
plt.show()

r2 = r2_score(y_test, pred)
print(f'R² Score: {r2:.4f}')
mae = mean_absolute_error(y_test, pred)
print(f'MAE: {mae:.4f}')
mae = mean_absolute_error(y_test, pred)
print(f'MAE: {mae:.4f}')
mse = mean_squared_error(y_test, pred)
print(f'MSE: {mse:.4f}')

plt.figure(figsize=(12, 6))
plt.plot(y_test, label='Actual Price')
plt.plot(pred, label='Predicted Price')
plt.xlabel('Time')
plt.ylabel('Price')
plt.legend()

model = Sequential([
    Bidirectional(GRU(100), input_shape=(seq_len, 2)),
    Dense(1)
])

model.compile(optimizer='adam', loss='mean_squared_error')

model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))
y_pred = model.predict(X_test).flatten()

residuals = y_test.flatten() - y_pred.flatten()
import matplotlib.pyplot as plt
import pandas as pd


plt.figure(figsize=(12, 5))
plt.plot(residuals, label='Residuals', color='purple')
plt.axhline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Residual Plot ')
plt.xlabel('Time')
plt.ylabel('Residual (Actual - Predicted)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()


plt.figure(figsize=(7, 5))
plt.hist(residuals, bins=30, color='skyblue', edgecolor='black')
plt.title('Distribution of Residuals')
plt.xlabel('Residual Value')
plt.ylabel('Frequency')
plt.axvline(0, color='red', linestyle='--')
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import gaussian_kde

residuals = np.array(residuals)

kde = gaussian_kde(residuals)
x_vals = np.linspace(residuals.min(), residuals.max(), 1000)
kde_vals = kde(x_vals)

plt.figure(figsize=(7, 5))
plt.hist(residuals, bins=30, color='skyblue', edgecolor='black', alpha=0.6, density=True)
plt.plot(x_vals, kde_vals, color='darkblue', linewidth=2, label='Density Curve')
plt.axvline(0, color='red', linestyle='--', label='Zero Error Line')
plt.title('Distribution of Residuals with Density Curve')
plt.xlabel('Residual Value')
plt.ylabel('Density')
plt.legend()
plt.tight_layout()
plt.show()

y_pred = model.predict(X_test).flatten()

r2= r2_score(y_test, y_pred)
print(f'R² Score: {r2:.4f}')
mae = mean_absolute_error(y_test, y_pred)
print(f'MAE: {mae:.4f}')
mae = mean_absolute_error(y_test, y_pred)
print(f'MAE: {mae:.4f}')
mse = mean_squared_error(y_test, y_pred)
print(f'MSE: {mse:.4f}')
rmse = np.sqrt(mse)
print(f'RMSE: {rmse:.4f}')

plt.figure(figsize=(12, 6))
plt.plot(y_test, label='Actual Price')
plt.plot(y_pred, label='Predicted Price')
plt.xlabel('Time')
plt.ylabel('Price')
plt.legend()
plt.grid()







